[
    "Audio Output: Moving the robot arm to the home position.\n\nRobot Output:\n````python\nself.robot.reach_named_position(\"home\")\n````",
    "Audio Output: Moving the robot arm up for 1 second.\nRobot Output:\n```python\nspeed = 0.05\nself.robot.publish_safe_twist([0,0,speed,0,0,0])\nrospy.sleep(1)\nself.robot.publish_safe_twist([0,0,0,0,0,0])\n```",
    "Audio Output: Moving the robot arm to the left for 2 seconds. \n\nRobot Output:\n````python\nspeed = 0.05\nself.robot.publish_safe_twist([0, speed, 0, 0, 0, 0])\nrospy.sleep(2)\nself.robot.publish_safe_twist([0, 0, 0, 0, 0, 0])\n````",
    "Audio Output: Move the robot arm backward for 2 seconds.\nRobot Output:\n````python\nspeed = 0.05\nself.robot.publish_safe_twist([-speed,0,0,0,0,0])\nrospy.sleep(2)\nself.robot.publish_safe_twist([0,0,0,0,0,0])\n````",
    "Audio Output: Adjusting the end effector to Z equals 0.2.\nRobot Output:\n````python\ngo_to_point_in_one_axis(self, 0.2, axis='z')\n````",
    "Audio Output: \"Rotate the end effector upside down.\"\n\nRobot Output:\n````python\nself.robot.publish_safe_twist([0,0,0,0,0,-20])\nrospy.sleep(9)\nself.robot.publish_safe_twist([0,0,0,0,0,0])\nrospy.sleep(4)\nself.robot.publish_safe_twist([0,0,0,0,0,20])\nrospy.sleep(9)\nself.robot.publish_safe_twist([0,0,0,0,0,0])\nrospy.sleep(4)\n````",
    "Audio Output: Orient the end effector to angles 90, 0, 90.\nRobot Output:\n```\ntarget_orientation = [90,0,90]\ngo_to_orientation(self, target_orientation, angular_direction=\"roll\")\n```",
    "Audio Output: Moving the end-effector to a specific pose.\n\nRobot Output:\n````python\ntarget_pose = [0.5, 0.2, 0.3, 180, 0, 90]\nmove_to_pose(self.current_pose, target_pose, linear_speed=0.05, angular_speed=10)\n````",
    "Audio Output: Moving along a predefined path with the end-effector.\n\nRobot Output:\n```python\ntrajectory = [[0.5, 0.2, 0.3], [0.6, 0.1, 0.4]]\ngo_through_trajectory(self, trajectory, linear_speed=0.05, angular_speed=10)\n```",
    "Audio Output: Tracking a moving object with the end-effector.\n\nRobot Output:\n```python\ntrack_object(self, \"hand\")\n```",
    "Audio Output: Open the end-effector.\n\nRobot Output:\n````python\nself.robot.example_send_gripper_open()\n````",
    "Audio Output: Close the end-effector with a force of 10 Newtons.\nRobot Output:\n```python\nself.robot.example_send_gripper_close(force=10, speed=0.1)\n```",
    "Audio Output: Close the end-effector at a force of 1 Newton.\nRobot Output:\n````python\nself.robot.example_send_gripper_close(force=1, speed=0.1)\n````",
    "Audio Output: Open the gripper to position zero point zero five.\nRobot Output:\n```\nself.robot.example_send_gripper_goto(pos=0.05)\n```",
    "Audio Output: Open the gripper to position zero point zero seven.\nRobot Output:\n```python\nself.robot.example_send_gripper_goto(pos=0.07)\n```",
    "Audio Output: Move the gripper to position 0.07.\nRobot Output:\n````python\nself.robot.example_send_gripper_goto(pos=0.07)\n````",
    "Audio Output: Moving the end effector to pose zero point seven zero zero point three at ninety degrees, zero degrees, ninety degrees.\n\nRobot Output:\n```python\ntarget_pose = [0.7, 0, 0.3, 90, 0, 90]\ngo_to_pose_rotate_all_directions(self, target_pose)\n```",
    "Audio Output: \"Pick up an object using specific affordance parameters.\"\nRobot Output:\n````python\naffordance_eef_to_object(self, target_pose=[0.2, 0, 0.1, 170, 10, 100], start_eef_position=0.055)\n````",
    "Audio Output: Locate the blue cup's position.\nRobot Output:\n````python\nclasses = [\"blue cup\"]\nupdate_classes_function(self, classes)\ntarget_position = get_object_position_with_wait(self, classes[0])\n````",
    "Audio Output: \"Scooping coffee at predefined location.\"\n\nRobot Output:\n```python\n# Scoop coffee at predefined location\ncoffee_location = [0.65, 0.15, 0.18, 90, -55, 90]\nsuccess = go_to_pose(self, coffee_location, angular_direction=\"pitch\")\nscoop(self)\nshake(self)\n```",
    "Audio Output: Moving to the coffee location.\n\nRobot Output: \n```python\ncoffee_location = [0.65,0.15,0.18,90,-55,90]\nsuccess = go_to_pose(self, coffee_location, angular_direction=\"pitch\")\n```",
    "Audio Output: Pour a specified amount of liquid.\n\nRobot Output:\n```\namount_to_pour = 50\npour(self, amount_to_pour)\n```",
    "Audio Output: Place an object down with controlled force.\nRobot Output: \n```\nput_down_object_with_force_control(self, [0.4, 0.2, 0.05])\n```",
    "Audio Output: \"Empty contents into the blue cup.\"\n\nRobot Output:\n```python\nempty_in_cup(self, \"blue cup\")\n```",
    "Audio Output: Locating and emptying contents into the blue cup.\n\nRobot Output:\n```python\nempty_in_cup(self, \"blue cup\")\n```",
    "Audio Output: Empty contents into the red bowl.\nRobot Output:\n````python\nempty_in_cup(self, \"red bowl\")\n````",
    "Audio Output: \"Take an item from a moving hand.\"\n\nRobot Output:\n````python\ntake_item(self, \"hand\")\n````",
    "Audio Output: Give item to a hand or recipient.\n\nRobot Output: \n\n```\ngive_item(self, \"hand\")\n```",
    "Audio Output: Taking an apple from a moving hand.\nRobot Output:\n````python\ntake_item(self, \"hand\")\n````",
    "Audio Output: Giving an apple to a hand or recipient.\n\nRobot Output:\n````python\ngive_item(self, \"hand\")\n````",
    "Audio Output: Opening door with handle number 1.\n\nRobot Output:\n````python\ndoor_type = open_door_handle(self, handle_number=1)\n````",
    "Audio Output: Close the door using handle number one.\n\nRobot Output:\n````python\nclose_door(self, handle_number=1)\n````",
    "Audio Output: The robot is going to pick up a spoon from the workspace.\nRobot Output:\n```python\nget_spoon(self)\n```",
    "Audio Output: Put back a spoon in the workspace.\n\nRobot Output:\n```python\nreturn_spoon(self)\n```",
    "Audio Output: The robot is going to pick up a kettle from the workspace.\nRobot Output:\n```python\nget_kettle(self)\n```",
    "Audio Output: Go to the kettle and grasp it.\n\nRobot Output:\n```python\nget_kettle(self)\n```",
    "Audio Output: The robot is going to put back the kettle in the workspace.\n\nRobot Output:\n````python\nreturn_kettle(self)\n````",
    "Audio Output: Retrieve a mug from a drawer.\nRobot Output:\n```\nget_mug_in_drawer(self)\n```",
    "Audio Output: The robot is going to place an object down in the workspace.\n\nRobot Output:\n````python\nput_down_object(self)\n````",
    "Audio Output: Pour a liquid into the green mug.\n\nRobot Output:\n````python\nobject_name = \"green mug\"\ntrack_and_pour(self, object_name, [0,0,0.3])\n````",
    "Audio Output: The robot is going to draw a sunflower shape.\n\nRobot Output:\n```python\nobject_name = \"sunflower\"\ndrawing(self, \"sunflower\")\n```",
    "Audio Output: Grasping the blue cup from above.\n\nRobot Output:\n```\nself.robot.example_send_gripper_open()\nobject_position = return_object_position(self, \"blue cup\")\nwaypoint1_position = [object_position[0], object_position[1], object_position[2] + 0.2]\nwaypoint2_position = object_position\ntrajectory = [waypoint1_position, waypoint2_position]\ngo_through_trajectory(self, trajectory)\n```",
    "Audio Output: Moving to grasp the blue cup.\n\nRobot Output:\n````python\nself.robot.example_send_gripper_open()\nobject_position = return_object_position(self, \"blue cup\")\nwaypoint1_position = [object_position[0], object_position[1], object_position[2] + 0.2]\nwaypoint2_position = object_position\ntrajectory = [waypoint1_position, waypoint2_position]\ngo_through_trajectory(self, trajectory)\nself.robot.example_send_gripper_close()\nself.robot.publish_safe_twist([0,0,0.05,0,0,0])\nrospy.sleep(1)\nself.robot.publish_safe_twist([0,0,0,0,0,0])\n````",
    "Audio Output: Moving to the red bowl from the front.\nRobot Output:\n````python\nobject_position = return_object_position(self, \"red bowl\")\nwaypoint1_position = [object_position[0] - 0.2, object_position[1], object_position[2]\nwaypoint2_position = object_position\ntrajectory = [waypoint1_position, waypoint2_position]\ngo_through_trajectory(self, trajectory)\n````",
    "Audio Output: Pour 100 grams of water into the blue cup.\nRobot Output:\n````python\nget_kettle(self)\nobject_position = return_object_position(self, \"blue cup\")\nwaypoint1_position = [object_position[0], object_position[1], object_position[2] + 0.3]\ntrajectory = [waypoint1_position]\ngo_through_trajectory(self, trajectory)\namount_to_pour = 100\npour(self, amount_to_pour)\n````",
    "Audio Output: Finding a cup and placing it down for pouring.\n\nRobot Output:\n````python\nfound_cup = False\nfor drawer in draws and not found_cup:\n    open_drawer()\n    found_cup = get_feedback_from_image_or_user()\n    if not found_cup():\n        close_drawer()\n    else:\n        grasp_cup()\n        put_cup_down()\n        close_drawer()\n````",
    "Audio Output: Pour 20 grams of water into the blue cup.\nRobot Output:\n```python\nget_kettle(self)\nobject_position = return_object_position(self, \"blue cup\")\nwaypoint1_position = [object_position[0], object_position[1], object_position[2] + 0.3]\ntrajectory = [waypoint1_position]\ngo_through_trajectory(self, trajectory)\namount_to_pour = 20\npour(self, amount_to_pour)\n```",
    "Audio Output: Open and close two specified drawers.\n\nRobot Output:\n``python\ndoor_type = open_door_handle(self, handle_number=1)\nclose_door(self, handle_number=1)\ndoor_type = open_door_handle(self, handle_number=2)\nclose_door(self, handle_number=2)\n```",
    "Audio Output: Scooping coffee into purple mug.\n\nRobot Output:\n````python\nget_spoon(self)\ngo_to_coffee(self)\nscoop(self)\nshake(self)\nempty_in_cup(self, \"purple mug\")\nreturn_spoon(self)\n````",
    "Audio Output: The robot is going to draw a specified shape.\n\nRobot Output:\n```python\n# Ensure end-effector is holding a pen\ntake_item(self, \"hand\")\n# Draw the specified shape\ndrawing(self)\n# Return the pen to the hand\ngive_item(self, \"hand\")\n```",
    "Audio Output: Moving the end-effector to the kettle.\nRobot Output:\n````python\nget_kettle(self)\n````",
    "Audio Output: Shake the end effector to mix contents.\n\nRobot Output:\n````python\nself.robot.publish_safe_twist([0, 0, 0, 0, 0, -20])\nrospy.sleep(4)\nself.robot.publish_safe_twist([0, 0, 0, 0, 0, 20])\nrospy.sleep(4)\nself.robot.publish_safe_twist([0, 0, 0, 0, 0, 0])\n````",
    "Audio Output: Adjust end-effector for precise object pickup.\nRobot Output:\n````python\naffordance_eef_to_object(self, target_pose=[0.2, 0, 0.1, 170, 10, 100], start_eef_position=0.055)\n````",
    "Audio Output: Moving to a specific position and awaiting coordination.\n\nRobot Output:\n```python\nspecific_position = [0.5, 0.2, 0.3]\ngo_through_trajectory(self, [specific_position], linear_speed=0.05, angular_speed=10)\n```",
    "Audio Output: Performing a controlled move to avoid obstacles.\n\nRobot Output:\n````python\nwaypoint1_position = [0.5, 0.2, 0.3]\nwaypoint2_position = [0.6, 0.1, 0.4]\ntrajectory = [waypoint1_position, waypoint2_position]\ngo_through_trajectory(self, trajectory, linear_speed=0.05, angular_speed=10)\n````",
    "Audio Output: Positioning end-effector for delicate tasks.\nRobot Output:\n````python\n# Example code snippet to position the end-effector for delicate tasks\ntarget_pose = [0.5, 0.2, 0.3, 180, 0, 90]\nmove_to_pose(self.current_pose, target_pose, linear_speed=0.05, angular_speed=10)\n````",
    "Audio Output: Open the gripper slowly for gentle release.\n\nRobot Output:\n```python\nself.robot.example_send_gripper_open(speed=0.1)\n```",
    "Audio Output: Closing the gripper slowly for careful picking.\n\nRobot Output:\n````python\nself.robot.example_send_gripper_close(force=10, speed=0.1)\n````",
    "Audio Output: Stabilizing end effector during operation.\nRobot Output:\n```python\ngo_to_point_in_one_axis(self, 0, axis='xyz') \n```",
    "Audio Output: Performing a safety check before operation.\n\nRobot Output:\n````python\n# Conduct a safety check\nself.robot.example_safety_check()\n````",
    "Audio Output: Locating the red bowl using image recognition.\n\nRobot Output:\n````python\nobject_position = return_object_position(self, \"red bowl\")\nprint(\"Red bowl located at position: \", object_position)\n````",
    "Audio Output: \"Initiate pouring action with variable amounts.\"\n\nRobot Output:\n````python\namount_to_pour = 50  # Specify the desired amount to pour\npour(self, amount_to_pour)\n````",
    "Audio Output: Retrieve multiple objects in succession.\n\nRobot Output:\n````python\nget_spoon(self)\nget_kettle(self)\nget_mug_in_drawer(self)\n````",
    "Audio Output: The robot is going to move to the red bowl from the front.\n\nRobot Output:\n```python\nself.robot.example_send_gripper_open()\nobject_position = return_object_position(self, \"red bowl\")\nwaypoint1_position = [object_position[0] - 0.2, object_position[1], object_position[2]\nwaypoint2_position = object_position\ntrajectory = [waypoint1_position, waypoint2_position]\ngo_through_trajectory(self, trajectory)\n```",
    "Audio Output: Performing repeatable motion sequence for assembly.\n\nRobot Output:\n````python\n# This is just a placeholder, please choose the specific sequence from the documentation to use for assembly\n# Example:\nget_kettle(self)\nobject_position = return_object_position(self, \"blue cup\")\nwaypoint1_position = [object_position[0], object_position[1], object_position[2] + 0.3]\ntrajectory = [waypoint1_position]\ngo_through_trajectory(self, trajectory)\namount_to_pour = 100\npour(self, amount_to_pour)\n````",
    "Audio Output: Validate the object's position before picking.\n\nRobot Output:\n````python\nobject_position = return_object_position(self, \"desired_object\")\nif object_position is not None:\n    # Object is detected\n    # Add picking up logic here\n    pass\nelse:\n    # Object not detected, handle the case accordingly\n    pass\n````",
    "Audio Output: The robot will track and pour into the green mug.\n\nRobot Output:\n```python\nobject_name = \"green mug\"\ntrack_and_pour(self, object_name, [0,0,0.3])\n```",
    "Audio Output: \"Recognize different types of objects based on visual cues.\"\nRobot Output: \n```python\nclasses = [\"object1\", \"object2\", \"object3\"]\nupdate_classes_function(self, classes)\n```",
    "**Audio Output:** \"Following a user-defined path for custom operations.\"\n\n**Robot Output:**\n```python\n# Custom operation following a user-defined path\ndef custom_path_operation():\n    # Define custom path waypoints\n    waypoints = [[0.5, 0.2, 0.3], [0.6, 0.1, 0.4], [0.7, 0.2, 0.3]]\n\n    # Move through custom trajectory\n    go_through_trajectory(self, waypoints, linear_speed=0.05, angular_speed=10)\n\n# Call the custom path operation function\ncustom_path_operation()\n```",
    "Audio Output: Track fast-moving objects continuously.\n\nRobot Output:\n```python\ntrack_object(self, \"fast-moving object\")\n```",
    "Audio Output: The robot arm will grasp the blue cup from above.\n\nRobot Output:\n```python\nself.robot.example_send_gripper_open()\nobject_position = return_object_position(self, \"blue cup\")\nwaypoint1_position = [object_position[0], object_position[1], object_position[2] + 0.2]\nwaypoint2_position = object_position\ntrajectory = [waypoint1_position, waypoint2_position]\ngo_through_trajectory(self, trajectory)\n```",
    "Audio Output: Performing a complex sequence of movements for operation.\nRobot Output:\n````python\n# Example code for executing a sequence of movements for a complex operation\nself.robot.example_send_gripper_open()\nobject_position = return_object_position(self, \"blue cup\")\nwaypoint1_position = [object_position[0], object_position[1], object_position[2] + 0.2]\nwaypoint2_position = object_position\ntrajectory = [waypoint1_position, waypoint2_position]\ngo_through_trajectory(self, trajectory)\nself.robot.example_send_gripper_close()\nself.robot.publish_safe_twist([0,0,0.05,0,0,0])\nrospy.sleep(1)\nself.robot.publish_safe_twist([0,0,0,0,0,0])\n````",
    "Audio Output: Checking object integrity during interactions.\nRobot Output:\n```python\nmonitor_object_integrity(self)\n```",
    "Audio Output: The robot is going to provide haptic feedback to ensure safety in gripping.\n\nRobot Output:\n```python\n# Provide haptic feedback for safety in gripping\ndef provide_haptic_feedback_for_gripping(self):\n    haptic_feedback = \"Ensure safety when gripping\"\n    self.robot.send_haptic_feedback(haptic_feedback)\n```",
    "Audio Output: \"Moving to specified pose.\"\n\nRobot Output:\n````python\n# Real-time adjustment based on user input\ndef move_to_specified_pose(self, pose):\n    go_to_pose(self, pose, linear_speed=0.05, angular_speed=10)\n    \n# User input for the target pose\ntarget_pose = [0.6, 0.1, 0.4, 90, 0, 90]\nmove_to_specified_pose(target_pose)\n````",
    "Audio Output: Recording and playback movements for training purposes.\n\nRobot Output:\n```python\n# Recording Movements\nrecorded_trajectory = []\nwhile recording:\n    current_position = self.robot.get_current_position()\n    recorded_trajectory.append(current_position)\n# Playback Movements\nfor position in recorded_trajectory:\n    self.robot.move_to_position(position)\n```",
    "Audio Output: The robot is going to conduct efficiency tests for various movement parameters.\n\nRobot Output:\n````python\n# Efficiency test for various movement parameters\nobject_position = return_object_position(self, \"test_object\")\nwaypoint1_position = [object_position[0], object_position[1], object_position[2] + 0.2]\nwaypoint2_position = object_position\ntrajectory = [waypoint1_position, waypoint2_position]\ngo_through_trajectory(self, trajectory)\n# Additional steps or measurements can be added for efficiency testing\n# Ensure to always follow safety guidelines mentioned in the documentation\n````",
    "Audio Output: Synchronize movements with user commands.\n\nRobot Output:\n````python\n# Synchronize movements with user commands\nwaypoint1_position = [0.2, 0.1, 0.3]\nwaypoint2_position = [0.3, 0.2, 0.3]\ntrajectory = [waypoint1_position, waypoint2_position]\ngo_through_trajectory(self, trajectory)\n````",
    "Audio Output: Optimize energy consumption during operations.\nRobot Output:\n````python\n# Optimize energy consumption\nminimize_energy_consumption(self)\n````",
    "Audio Output: Perform periodic tasks.\n\nRobot Output:\n```python\nimport time\n\n# Define the sequence of tasks to be repeated periodically\ntasks = [task1, task2, task3]\n\n# Define the frequency of task repetition in seconds\nfrequency = 60\n\n# Infinite loop to repeat tasks periodically\nwhile True:\n    for task in tasks:\n        # Execute the task\n        task()\n        # Wait for the defined frequency\n        time.sleep(frequency)\n```"
]